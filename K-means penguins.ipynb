{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "55b66222",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 1️⃣ Librerías\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpandas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mpd\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpreprocessing\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m StandardScaler\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msklearn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mcluster\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m KMeans\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "# 1️⃣ Librerías\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Para gráficos más bonitos\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# 2️⃣ Cargar dataset\n",
    "df = pd.read_csv(\"penguins.csv\")  # Cambia el nombre según tu archivo\n",
    "\n",
    "# 3️⃣ Selección de variables numéricas para clustering\n",
    "features = [\n",
    "    \"bill_length_mm\", \"bill_depth_mm\", \"flipper_length_mm\", \"body_mass_g\"\n",
    "]\n",
    "\n",
    "X = df[features]\n",
    "\n",
    "# 4️⃣ Escalado de los datos\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# 5️⃣ Determinar número de clusters con el método del codo\n",
    "inertia = []\n",
    "K_range = range(1, 11)\n",
    "for k in K_range:\n",
    "    kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "    kmeans.fit(X_scaled)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Graficar método del codo\n",
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(K_range, inertia, marker='o')\n",
    "plt.xlabel(\"Número de clusters\")\n",
    "plt.ylabel(\"Inercia\")\n",
    "plt.title(\"Método del codo para determinar K óptimo\")\n",
    "plt.show()\n",
    "\n",
    "# 6️⃣ Aplicar K-means con K elegido (por ejemplo, K=4)\n",
    "k = 4\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "\n",
    "# 7️⃣ Revisar centros de los clusters (valores escalados)\n",
    "centers = pd.DataFrame(scaler.inverse_transform(kmeans.cluster_centers_), columns=features)\n",
    "print(\"Centros de los clusters:\")\n",
    "print(centers)\n",
    "\n",
    "# 8️⃣ Visualización de clusters en dos dimensiones (p. ej., \"bill_length_mm\" vs \"body_mass_g\")\n",
    "plt.figure(figsize=(8,6))\n",
    "sns.scatterplot(\n",
    "    x='bill_length_mm',\n",
    "    y='body_mass_g',\n",
    "    hue='cluster',\n",
    "    palette='Set2',\n",
    "    data=df,\n",
    "    alpha=0.7\n",
    ")\n",
    "plt.title(\"Clusters de canciones de Penguins (bill_length_mm vs body_mass_g)\")\n",
    "plt.show()\n",
    "\n",
    "# 9️⃣ Opcional: analizar qué géneros predominan en cada cluster\n",
    "genre_cluster = df.groupby('cluster')['species'].value_counts().unstack(fill_value=0)\n",
    "print(genre_cluster)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e971fc",
   "metadata": {},
   "source": [
    "# Interpretación detallada de los resultados de K-means y los clusters\n",
    "A continuación se presenta una interpretación dinámica y detallada de los resultados obtenidos tras aplicar el algoritmo K-means al dataset de canciones de Spotify:\n",
    "## 1. ¿Qué significa cada cluster?\n",
    "Cada cluster agrupa canciones con características similares en las variables seleccionadas. Los centros de los clusters (mostrados en la tabla anterior) representan el perfil promedio de cada grupo. Por ejemplo:\n",
    "- **Cluster 0:** Describe aquí el perfil según los valores del centro (por ejemplo, canciones muy bailables y energéticas).\n",
    "- **Cluster 1:** Describe el perfil (por ejemplo, canciones más tranquilas y acústicas).\n",
    "- **Cluster 2:** ...\n",
    "- **Cluster 3:** ...\n",
    "(Sustituye cada descripción con los patrones observados en los centros de los clusters).\n",
    "## 2. ¿Por qué se eligió K=4?\n",
    "El método del codo mostró que a partir de K=4 la reducción de la inercia es menos pronunciada, lo que indica que 4 clusters es un buen balance entre simplicidad y explicación de la variabilidad de los datos.\n",
    "## 3. ¿Qué nos dicen los centros de los clusters?\n",
    "Los centros muestran los valores promedio de cada variable para las canciones de cada grupo. Analizar estos valores permite identificar qué distingue a cada cluster (por ejemplo, un cluster puede tener mayor tempo y energía, otro mayor acousticness, etc.).\n",
    "## 4. ¿Cómo interpretar la visualización?\n",
    "El gráfico de dispersión (danceability vs energy) permite ver cómo se agrupan y separan los clusters en dos dimensiones clave. Si los grupos están bien separados, el clustering es efectivo.\n",
    "## 5. ¿Qué géneros predominan en cada cluster?\n",
    "El análisis de géneros por cluster ayuda a entender qué estilos musicales son más frecuentes en cada grupo, lo que puede ser útil para recomendaciones o segmentación de audiencias.\n",
    "## 6. Reflexión final sobre K-means\n",
    "K-means es útil para descubrir patrones y segmentar datos, pero la interpretación depende de la selección de variables y la estandarización. Es recomendable revisar los centros y la composición de cada cluster para obtener conclusiones accionables."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
